{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients from sklearn: \n",
      " [[1.93459824]]\n",
      "\n",
      "Intercept from sklearn: \n",
      " [0.53612066]\n",
      "\n",
      "Coefficients from gradient descent algorithm: \n",
      " 1.7370079999504038\n",
      "\n",
      "Intercept from gradient descent algorithm: \n",
      " 0.5065007056293782\n",
      "\n",
      "Iterations \n",
      " 207\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Cost function for the linear regression that we will try to optimize.\n",
    "def LR_cost_function (alpha, beta, x, y):\n",
    "    '''Return the cost for a given line and data.\n",
    "    \n",
    "    Alpha and beta are the coeficients that describe the fit line line, while\n",
    "    x and y are lists or arrays with the x and y value of each data point.\n",
    "    '''\n",
    "    error = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        point_error = (y[i] - (alpha + beta * x[i])) ** 2\n",
    "        error += point_error\n",
    "    return error / n\n",
    "\n",
    "\n",
    "# Function we'll call each iteration (or step) of the gradient algorithm.\n",
    "def step (alpha_cur, beta_cur, learning_rate, x, y):\n",
    "    '''Move downhill from a current cost function to a new, more optimal one.'''\n",
    "    alpha = 0\n",
    "    beta = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        # Partial derivative of the intercept.\n",
    "        point_alpha = -(2 / n) * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        alpha += point_alpha\n",
    "        \n",
    "        # Partial derivative of the slope.\n",
    "        point_beta = -(2 / n) * x[i] * (y[i] - ((alpha_cur + beta_cur * x[i])))\n",
    "        beta += point_beta\n",
    "        \n",
    "    new_alpha = alpha_cur - learning_rate * alpha \n",
    "    new_beta = beta_cur - learning_rate * beta\n",
    "    return [new_alpha, new_beta]\n",
    "\n",
    "# These constants correspond to the decision-points described above.\n",
    "# How many steps to take.\n",
    "stop = 1000\n",
    "\n",
    "# How far to move with each step.\n",
    "learning_rate = .005\n",
    "\n",
    "# Starting values for intercept and slope \n",
    "alpha_start = 0\n",
    "beta_start = 0\n",
    "\n",
    "# Time to make some data!\n",
    "x = np.random.normal(0, 1, 100)\n",
    "y = x * 2 + np.random.sample(100)\n",
    "\n",
    "# Fit an true minimum regression using solved equations.\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x.reshape(-1, 1), y.reshape(-1, 1))\n",
    "\n",
    "print('\\nCoefficients from sklearn: \\n', regr.coef_)\n",
    "print('\\nIntercept from sklearn: \\n', regr.intercept_)\n",
    "\n",
    "\n",
    "# Now fit an iteratively optimized regression using your custom gradient\n",
    "# descent algorithm.\n",
    "\n",
    "# Storing each iteration to inspect later.\n",
    "all_error=[]\n",
    "\n",
    "# Provide starting values.\n",
    "alpha = alpha_start\n",
    "beta = beta_start\n",
    "\n",
    "#Run the algorithm.\n",
    "for iter in range(stop):\n",
    "    \n",
    "    # Take a step, assigning the results of our step function to feed into\n",
    "    # the next step.\n",
    "    alpha, beta = step(alpha, beta, learning_rate, x, y)\n",
    "    \n",
    "    # Calculate the error.\n",
    "    error = LR_cost_function(alpha, beta, x, y)\n",
    "    \n",
    "    # Store the error to instpect later.\n",
    "    all_error.append(error)\n",
    "    \n",
    "    if len(all_error) > 1:\n",
    "        if abs(error - all_error[-2]) < 0.001:\n",
    "            break \n",
    "            \n",
    "    \n",
    "print('\\nCoefficients from gradient descent algorithm: \\n', beta)\n",
    "print('\\nIntercept from gradient descent algorithm: \\n', alpha)\n",
    "print('\\nIterations \\n', len(all_error))\n",
    "\n",
    "plt.plot(all_error, 'o', ms=.4)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error scores for each iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
